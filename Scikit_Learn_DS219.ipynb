{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Scikit-Learn DS219.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmouts/PPS_PatternRecognition/blob/main/Scikit_Learn_DS219.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxZZbIVMj_4L"
      },
      "source": [
        "\n",
        "![alt text](http://www.lib.unipi.gr/images/home/logo_calibri_en.png)\n",
        "# Αναγνώριση Προτύπων\n",
        "## Scikit-Learn\n",
        "\n",
        "### Πανεπιστήμιο Πειραιώς\n",
        "### Τμήμα Ψηφιακών Συστημάτων"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-dG2oeRj_4N"
      },
      "source": [
        "Η Python είναι μια εύκολη στην εκμάθηση και πανίσχυρη γλώσσα προγραμματισμού. Διαθέτει αποδοτικές υψηλού επιπέδου δομές δεδομένων και μια απλή προσέγγιση στον αντικειμενοστρεφή προγραμματισμό. Το κομψό συντακτικό, η λειτουργία dynamic typing και η interpreted φύση της, την καθιστούν ιδανική για scripting και για τη γρήγορη ανάπτυξη εφαρμογών στις περισσότερες πλατφόρμες.\n",
        "\n",
        "Ιδιαίτερα στον τομέα της μηχανικής μάθησης η python έχει αναδειχθεί πρωταθλητής λόγω του τεράστιου αριθμού βιβλιοθηκών που υπάρχουν αλλά και λόγω της απλότητας της, εξοικονομώντας έτσι χρόνο ώστε να επικεντρωθεί ο χρήστης σε άλλες πλευρές του προβλήματος που καλείται να επιλύσει."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anvtQv8wj_4O"
      },
      "source": [
        "### Βασικές Λειτουργίες\n",
        "#### Δομές Δεδομένων"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWvQMZrdj_4P"
      },
      "source": [
        "#Ανάθεση μεταβλητής\n",
        "x = 5\n",
        "print(x)\n",
        "\n",
        "y = 'A'\n",
        "print(y)\n",
        "\n",
        "print(x,y)\n",
        "print(type(y))\n",
        "\n",
        "#Slicing (start:stop:step)\n",
        "x = 'Hello'\n",
        "print(x[1])\n",
        "print(len(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4VgDhdWj_4Y"
      },
      "source": [
        "#Δημιουργία λίστας\n",
        "list1 = []\n",
        "print(type(list1))\n",
        "\n",
        "list1 = [1, 2, 3, 4, 5, 6, 7, 'str']\n",
        "print(list1)\n",
        "print(len(list1))\n",
        "\n",
        "#Slicing (start:stop:step)\n",
        "print(list1[1])\n",
        "print(list1[0:])\n",
        "print(list1[0:4])\n",
        "print(list1[:-2])\n",
        "print(list1[6::-1])\n",
        "print(list1[6:0:-1])\n",
        "print(len(list1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9jrDSH9j_4c"
      },
      "source": [
        "#Δημιουργία Tuple\n",
        "tuple1 = 4, 5, 6\n",
        "print(tuple1)\n",
        "print(type(tuple1))\n",
        "\n",
        "tuple1 = (4, 5, 6), 1, 'd', ('e', 'd')\n",
        "print(tuple1)\n",
        "\n",
        "print(tuple1[0])\n",
        "print(tuple1[2])\n",
        "print(tuple1[3])\n",
        "print(tuple1[0:3])\n",
        "print(len(tuple1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d12k6eBEj_4i"
      },
      "source": [
        "#Δημιουργία λεξικού\n",
        "dict1 = {}\n",
        "print(type(dict1))\n",
        "\n",
        "dict1 = {'one': 1, 'two': 2, 3: 5, ('d',2):6}\n",
        "dict1['four'] = 3\n",
        "print(dict1['one'], dict1['two'], dict1[3], dict1['four'])\n",
        "print(dict1.items())\n",
        "print(len(dict1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArfCwLeej_4m"
      },
      "source": [
        "#Δημιουργία Set\n",
        "set1 = {1, 2, 3, 4, 5, 6}\n",
        "set2 = {2, 3, 4, 7, 9, 10}\n",
        "print(type(set1))\n",
        "\n",
        "#Πράξεις Συνόλων\n",
        "print(set1 | set2) #Ένωση\n",
        "print(set1 & set2) #Τομή\n",
        "print(set1 - set2) #Διαφορά\n",
        "print(set1 ^ set2) #XOR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d9XVXDPj_4s"
      },
      "source": [
        "#### Συναρτήσεις\n",
        "Οι συναρτήσεις είναι κομμάτια κώδικα οργανωμένα σε μπλόκς που στοχεύουν στην καλύτερη οργάνωση της εφαρμογής αλλά και στην επαναχρησιμοποιηση του κώδικα. H python δεν απαιτεί σύμβολα για την δήλωση των μπλοκς αλλά χρησιμοποιεί στοίχιση στις περιπτώσεις συναρτήσεων, κλάσεων και δομών επανάληψης."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FurY6PzMj_4u"
      },
      "source": [
        "#Δημιουργία Συνάρτησης\n",
        "def addition(num1, num2):\n",
        "    sum1 = num1 +num2\n",
        "    return sum1\n",
        "\n",
        "print(type(addition))\n",
        "\n",
        "s = addition(4, 5)\n",
        "print(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHITaJOOj_4w"
      },
      "source": [
        "#### Κλάσεις\n",
        "Οι κλάσεις όπως και στις υπόλοιπες γλώσσες προγραμματισμού στοχεύουν στην ομαδοποίηση των λειτουργιών και των χαρακτηριστικών ενός αντικειμένου. Με αυτήν την ομαδοποίηση γίνεται ευκολότερη η επαναχρησιμοποίηση του ίδιου κώδικα αλλά και οργανώνεται καλύτερα η εφαρμογή. Οι κλάσεις αποτελούν το σχεδιάγραμμα για την κατασκευή ενός αντικειμένου ενώ με την κλήση ενός initializer αρχικοποιείται ένα αντικείμενο. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfKjg1_3j_4x"
      },
      "source": [
        "import math\n",
        "\n",
        "#Δημιουργία Κλάσης\n",
        "class Complex:\n",
        "    \n",
        "    def __init__(self, imaginary, real):\n",
        "        self.i = imaginary\n",
        "        self.r = real\n",
        "    \n",
        "    def magnitude(self):\n",
        "        mag = math.sqrt(self.i**2 + self.r**2)\n",
        "        return mag\n",
        "    \n",
        "number = Complex(4,5)\n",
        "print(number)\n",
        "\n",
        "print(number.magnitude())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OGzR848j_43"
      },
      "source": [
        "#### Δομές επανάληψης"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZReWsEkj_43"
      },
      "source": [
        "#Δομή ελέγχου if elif else\n",
        "def age_restrictions(age):\n",
        "    if age < 18:\n",
        "        print('You are a minor!')\n",
        "    elif age >= 18 and age < 21:\n",
        "        print('You can get a beer!')\n",
        "    else:\n",
        "        print('You can drink and play at a casino!')\n",
        "\n",
        "age_restrictions(21)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4L0IeZKej_47"
      },
      "source": [
        "#Δομή επανάληψης while\n",
        "x = True\n",
        "i = 0\n",
        "\n",
        "while x:\n",
        "    \n",
        "    if i == 5:\n",
        "        x = False\n",
        "    i += 1\n",
        "    print('Inside of the while loop: ', x)\n",
        "    \n",
        "print('Outside of the while loop: ', x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wkEEo2gj_49"
      },
      "source": [
        "#Δομή επανάληψης for\n",
        "cars = ['Polo', 'Saxo', 'Punto', 'Golf']\n",
        "\n",
        "for x in cars:\n",
        "    print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40d52d41j_5A"
      },
      "source": [
        "#Δομή επανάληψης for in range\n",
        "\n",
        "for x in range(4): #(start:stop:step)\n",
        "    print(x)\n",
        "\n",
        "    \n",
        "print('\\n')\n",
        "\n",
        "for x in range(0, 31, 2):\n",
        "  if x % 5 == 0:\n",
        "    print(x)\n",
        "  else:\n",
        "    print('mod is not zero')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuD7-HZbq3l4"
      },
      "source": [
        "#### Άσκηση #1\n",
        "Να κατασκευαστεί μια συνάρτηση που να δέχεται σαν όρισμα ένα string και να το εκτυπώνει σε κάθε γραμμή χωρίς το αρχικό γράμμα."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-2GqbUvq2vz"
      },
      "source": [
        "\n",
        "\n",
        "# Test String'Eeeeccchhhoooo'\n",
        "# Output:\n",
        "# Eeeeccchhhoooo\n",
        "# eeeccchhhoooo\n",
        "# eeccchhhoooo\n",
        "# eccchhhoooo\n",
        "# ccchhhoooo\n",
        "# cchhhoooo\n",
        "# chhhoooo\n",
        "# hhhoooo\n",
        "# hhoooo\n",
        "# hoooo\n",
        "# oooo\n",
        "# ooo\n",
        "# oo\n",
        "# o"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqtNfo-Vj_5E"
      },
      "source": [
        "## Scikit-Learn\n",
        "![alt text](https://www.inria.fr/var/inria/storage/images/medias/saclay/innovation-images/chapo/saclay-riidata-scikit-learn-260x195/1111030-1-fre-FR/saclay-riidata-scikit-learn-260x195_vignette.jpg)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEd8_b1Xj_5F"
      },
      "source": [
        "#Εγκατάσταση των απαραίτητων βιβλιοθηκών(modules) στο παρόν Jupyter notebook.\n",
        "import sys\n",
        "\n",
        "!pip install numpy\n",
        "!pip install  scipy\n",
        "!pip install  matplotlib\n",
        "!pip install  scikit-learn\n",
        "\n",
        "import numpy as np\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2lyM35qj_5I"
      },
      "source": [
        "Η βιβλιοθήκη sklearn βασίζεται στις βιβλιοθήκες numpy, scipy και matplotlib. Το module scipy είναι μια μαθηματική βιβλιοθήκη που παρέχει ευκολίες για υπολογισμούς μαθηματικών ποσοτήτων, ενώ η matplotlib είναι μια βιβλιοθήκη οπτικοποίησης των αποτελεσμάτων. Τέλος η βιβλιοθήκη numpy είναι μια απο τις βασικότερες επιστημονκές βιβλιοθήκες της Python και επιτρέχει την διαχείριση πολυδιάστατων πινάκων δεδομένων. Η βασική δομή δεδομένων της numpy είναι το ndarray(n dimentional array) που είναι ένας πίνακας, ενώ τα στοιχεία του ndarray πρέπει να είναι του ίδιου τύπου."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAZeIcbst9Pu"
      },
      "source": [
        "#### Numpy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqF9i384j_5J"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "b = np.array([1, 2, 3, 4])\n",
        "print(b)\n",
        "print(b.size)\n",
        "print(b[1])\n",
        "\n",
        "a = np.arange(15).reshape(3, 5) # Κατασκευή ενός array με τιμές απο το 0 εώς το 15 και μετατροπή σε πίνακα (3x5)\n",
        "\n",
        "print(a)\n",
        "print(a.shape)# Διαστάσεις του πίνακα\n",
        "print(a.ndim) # Άξονες του πίνακα\n",
        "print(a[1][1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLP8MaBEj_5N"
      },
      "source": [
        "# Κατασκευή πίνακα μηδενικών (5x5)\n",
        "zeros = np.zeros((5,5))\n",
        "print(zeros)\n",
        "\n",
        "# Κατασκευή πίνακα άσων(6x6)\n",
        "ones = np.ones((6,6))\n",
        "print(ones)\n",
        "\n",
        "# Κατασκευή μοναδιαίου πίνακα (7x7)\n",
        "eye = np.eye(7)\n",
        "print(eye)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNmP3G5Jl_95"
      },
      "source": [
        "#### Άσκηση #2\n",
        "Να κατασκευαστεί μια συνάρτηση που να δέχεται σαν όρισμα έναν πίνακα(3x3), να ελέγχει άν είναι (3x3) και να υπολογίζει την ορίζουσα του ώς προς την πρώτη γραμμή.\n",
        "\n",
        "\n",
        "![alt text](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRWV6e-f1iazwVm9HTGsAA-CWA9Dl8f6j4p22ie-jszXdOu2VwK)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZjn1IAJwUuz"
      },
      "source": [
        "\n",
        "\n",
        "#Test matrix\n",
        "# [[0 1 2]\n",
        "#  [3 4 5]\n",
        "#  [6 7 8]]\n",
        "# Output:\n",
        "#The determinant is  0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFvVWskxtdeE"
      },
      "source": [
        "#### Λειτουργίες SkLearn\n",
        "Η Scikit-learn(Sklearn) είναι μία πλήρης βιβλιοθήκη Python για Μηχανική Μάθηση. Περιλαμβάνει:\n",
        "\n",
        "* Εργαλεία Προεπεξεργασίας Δεδομένων\n",
        "* Μεθόδους Απομείωσης Διαστασιμότητας και Επιλογής Μοντέλου\n",
        "* Αλγορίθμους Παλινδρόμησης (Regression)\n",
        "* Αλγορίθμους Συσταδοποίησης (Clustering)\n",
        "* Αλγορίθμους Κατηγοριοποίησης (Classification)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKJ3TluCj_5S"
      },
      "source": [
        "Εκτός από τα παραπάνω εργαλεία, η βιβλιοθήκη περιλαμβάνει και μερικά κλασικά datasets τα οποία χρησιμοποιούνται για δοκιμές.\n",
        "* **Iris** (Κατηγοριοποίηση, 3 κλάσεις)\n",
        "* **Boston Housing** (Παλινδρόμηση, 13 Χαρακτηριστικά)\n",
        "* **Diabetes** (Παλινδρόμηση)\n",
        "* **Digits** (Κατηγοριοποίηση, 10 κλάσεις)\n",
        "* **Breast Cancer** (Κατηγοριοποίηση, 2 Κλάσεις)\n",
        "* **Wine** (Κατηγοριοποίηση, 3 κλάσεις)\n",
        "\n",
        "Τα dataset βρίσκονται στο module datasets του module sklearn:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sItccLOpj_5S"
      },
      "source": [
        "from sklearn import datasets\n",
        "\n",
        "#Το Iris Dataset περιλαμβάνει 150 παραδείγματα λουλουδιών που ανήκουν σε τρείς κατηγορίες\n",
        "#(Setosa, Versicolour, and Virginica). Τα χαρακτηριστικά τους χωρίζοναι σε 4 κατηγορίες\n",
        "#(Sepal Length, Sepal Width, Petal Length and Petal Width).\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data[:, :2]  #Παίρνουμε τις πρώτες δύο κατηγορίες χαρακτηριστικών\n",
        "y = iris.target\n",
        "\n",
        "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
        "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
        "\n",
        "\n",
        "#Οπτικοποίηση των παραδειγμάτων\n",
        "plt.figure(2, figsize=(8, 6))\n",
        "plt.clf()\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Set1,\n",
        "            edgecolor='k')\n",
        "plt.xlabel('Sepal length')\n",
        "plt.ylabel('Sepal width')\n",
        "\n",
        "plt.xlim(x_min, x_max)\n",
        "plt.ylim(y_min, y_max)\n",
        "plt.xticks(())\n",
        "plt.yticks(())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgtjwFp09Goh"
      },
      "source": [
        "### Preprocessing\n",
        "#### Standardization\n",
        "Η τυποποίηση των συνόλων δεδομένων είναι συχνό προαπαιτούμενο για πολλούς αλγορίθμους μηχανικής μάθησης. Πρακτικά προτιμάται η Γκαουσιανή κατανομή με μέση τιμή 0 και διασπορά 1 (Ν(0,1)). \n",
        "\n",
        "#### Scale to a range\n",
        "Αλλαγή της κλίμακας των δεδομένων ώστε όλες οι καταχωρήσεις να κυμαίνονται μεταξύ κάποιων ορίων.\n",
        "\n",
        "\n",
        "Άλλα είδη προεπεξεργασίας: Encoding categorical features, Discretization κ.α."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JjSP08Ij_5W"
      },
      "source": [
        "# Standardization\n",
        "from sklearn import preprocessing\n",
        "X_train = np.array([[ 1., -1.,  2.],\n",
        "                    [ 2.,  0.,  0.],\n",
        "                    [ 0.,  1., -1.]])\n",
        "X_scaled = preprocessing.scale(X_train)\n",
        "\n",
        "X_scaled "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjlxfwUt_5_n"
      },
      "source": [
        "# Scale to a range\n",
        "X_train = np.array([[ 1., -1.,  2.],\n",
        "                    [ 2.,  0.,  0.],\n",
        "                    [ 0.,  1., -1.]])\n",
        "\n",
        "preprocessing.minmax_scale(X_train, feature_range=(0, 1), axis=0, copy=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5X3QNYTBcR4"
      },
      "source": [
        "### Μέθοδοι Απομείωσης Διαστασιμότητας και Επιλογής Μοντέλου\n",
        "\n",
        "#### Principal component analysis (PCA)\n",
        "Η λογική αυτής της μεθόδου είναι η αναζήτηση καινούργιων αξόνων(λιγότερων) που να περιγράφουν όσο καλύτερα γίνεται το σύνολο δεδομένων. Το κριτήριο για την επιλογή των καινούργιων αξόνων θα είναι το μέτρο της διασποράς. Αφού εντοπιστεί ο άξονας με την μεγαλύτερη διασπορά αναζητείται ο επόμενος με κριτήριο και πάλι την τιμή της διασποράς αλλά και την καθετότητα στον πρώτο αφού θα περιγράφουν ένα νέο σύστημα αξόνων.![alt text](https://docs.opencv.org/3.1.0/pca_eigen.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItkIYXA9DAaU"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "target_names = iris.target_names\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "X_r = pca.fit(X).transform(X)\n",
        "\n",
        "# Percentage of variance explained for each components\n",
        "print('explained variance ratio (first two components): %s'\n",
        "      % str(pca.explained_variance_ratio_))\n",
        "\n",
        "plt.figure()\n",
        "colors = ['navy', 'turquoise', 'darkorange']\n",
        "lw = 2\n",
        "\n",
        "for color, i, target_name in zip(colors, [0, 1, 2], target_names):\n",
        "    plt.scatter(X_r[y == i, 0], X_r[y == i, 1], color=color, alpha=.8, lw=lw,\n",
        "                label=target_name)\n",
        "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
        "plt.title('PCA of IRIS dataset')\n",
        "\n",
        "plt.figure()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbiUiT66FJEB"
      },
      "source": [
        "#### Cross-validation: evaluating estimator performance\n",
        "Όταν εκπαιδεύεται ένας αλγόριθμος μηχανικής μάθησης ρυθμίζονται οι παράμετροι του έτσι ώστε να περιγράφει όσο πιο σωστά γίνεται τα δεδομένα. Για να ελεγχθεί ή απόδοση του αλγορίθμου σε νέα δεδομένα θα πρέπει να υπάρχει ένα σύνολο δεδομένων στο οποίο δέν έχει εκπαιδευτεί ο αλγόριθμος. Με αυτόν τον τρόπο μπορεί να ποσοτικοποιηθεί η ικανότητα του αλγορίθμου να γενικεύει και αποτρέπεται το overfitting.\n",
        "Μία τεχνική που χρησιμοποιείται για αυτόν τον σκοπό έιναι το Cross-Validation(CV) κατά το οποίο το αρχικό σύνολο δεδομένων χωρίζεται σε train set και test set όπου ο αλγόριθμοπς εκπαιδεύεται στο train set και στην συνέχεια δοκιμάζεται στο test set. Προεραιτικά υπάρχει η δυνατότητα να χωριστεί σε ένα ακόμη κομμάτι (validation set) το οποίο χρησιμοποιείται για την ρύθμιση των hyperparameters. Υπάρχουν πολλές παραλλαγές του CV όπως k-fold, leave one out, StratifiedKFold κ.α.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RuLHtvQF5KV"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "print(iris.data.shape, iris.target.shape)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    iris.data, iris.target, test_size=0.4, random_state=0)\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "\n",
        "print(X_test.shape, y_test.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0wCuSdmKRxA"
      },
      "source": [
        "#### Άσκηση #4\n",
        "Να αλλαχθεί η κλίμακα των στοιχείων του πίνακα a_features ώστε όλα να κυμαίνονται από 3 έως 15 και στην συνέχεια να χωριστεί σε train set και test set με ποσοστό 0.20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-6cQQRBMFSu"
      },
      "source": [
        "a_features = np.arange(0,20).reshape(10,2)\n",
        "\n",
        "b_target = np.arange(0,10).reshape(10,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBskctDuP0v5"
      },
      "source": [
        "### Διαδικασία εκπαίδευσης αλγορίθμων μηχανικής μάθησης\n",
        "Σε όλες τις εφαρμογές μηχανικής μάθησης η διαδικασία είναι σχετικά κοινή και με παρόμοιο τρόπο εφαρμόζεται και μέσω της βιβλιοθήκης Sklearn. \n",
        "* Στην αρχή θα πρέπει να αναλυθεί το πρόβλημα που πρέπει να επιλυθεί και να εξαχθούν τα σχετικά χαρακτηριστικά(features). \n",
        "* Στην συνέχεια θα γίνει τυχόν προεπεξεργασία των δεδομένων, μείωση των διαστάσεων ή επιλογή χαρακτηριστικών έτσι ώστε να καταλήξει σε ένα αποδοτικό σύνολο δεδομένων.\n",
        "* Έπειτα θα δημιουργηθεί το μοντέλο που θα χρησιμοποιηθεί και θα εκπαιδευτεί στο σύνολο δεδομένων εκπαίδευσης.\n",
        "* Τέλος θα εκτιμηθεί η απόδοση του στο σύνολο δεδομένων δοκιμής ώστε να επιλεχθεί το βέλτιστο μοντέλο.\n",
        "\n",
        "\n",
        "### Regression (Παλινδρόμηση)\n",
        "Η παλινδρόμηση χρησιμοποιείται για να μοντελοποιήσει την σχέση των ανεξάρτητων μεταβλητών(features) με την εξαρτημένη ενός παραδείγματος(target). Χρησιμοποιείται για συνεχείς τιμές μεταβλητής στόχου, ενώ μπορεί να προβλέψει την τιμή στόχου εάν οι ανεξάρτητες μεταβλητές περάσουν μέσα από το εκπαιδευμένο μοντέλο.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xz7uipTPdxKa"
      },
      "source": [
        "#Γραμμική παλινδρόμηση(RSS)\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Φορτωνεται το Boston Dataset\n",
        "boston = datasets.load_boston()\n",
        "\n",
        "# Χρησιμοποιείται το ένα χαρακτηριστικό(αριθμός δωματίων)\n",
        "boston_x = boston.data[:, 5].reshape(-1, 1)\n",
        "\n",
        "# Χωρίζονται τα δεδομένα σε train/test\n",
        "boston_x_train = boston_x[:-400]\n",
        "boston_x_test = boston_x[-400:]\n",
        "\n",
        "# Χωρίζονται οι μεταβλητές στόχου σε train/test\n",
        "boston_y_train = boston.target[:-400]\n",
        "boston_y_test = boston.target[-400:]\n",
        "\n",
        "# Δημιουργείται το μοντέλο\n",
        "lm = linear_model.LinearRegression()\n",
        "\n",
        "# Εκπαιδεύεται στα δεδομένα επαίδευσης\n",
        "lm.fit(boston_x_train, boston_y_train)\n",
        "\n",
        "# Προβλέπει την μεταβλητή στόχου για το σύνολο δεδομένων δοκιμής\n",
        "boston_y_pred = lm.predict(boston_x_test)\n",
        "\n",
        "# The coefficients\n",
        "print('Coefficients: \\n', lm.coef_, '\\n', lm.intercept_)\n",
        "\n",
        "# The mean squared error\n",
        "print(\"Mean squared error: %.2f\"\n",
        "      % mean_squared_error(boston_y_test, boston_y_pred))\n",
        "\n",
        "# Plot\n",
        "plt.scatter(boston_x_test, boston_y_test,  color='black')\n",
        "plt.plot(boston_x_test, boston_y_pred, color='blue', linewidth=3)\n",
        "\n",
        "plt.xticks(())\n",
        "plt.yticks(())\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvaPIWDUj_ed"
      },
      "source": [
        "### Συσταδοποίηση\n",
        "Οι αλγόριθμοι συσταδοποίησης επιχειρούν την ανάθεση σε μία ομάδα όλων των παραδειγμάτων σύμφωνα με κάποιο κριτήριο απόστασης. Οι αλγόριθμοι αυτοί ανήκουν στην κατηγορία της μη επιβλεπόμενης μάθησης, καθώς δεν απαιτείται η ύπαρξη label για την ομαδοποίηση. Πολλές φορές χρησιμοποιούνται για την εύρεση τυχόντων μοτίβων στα δεδομένα. \n",
        "\n",
        "Ένα παράδειγμα συσταδοποίησης είναι η ομαδοποίηση των διαφόρων ειδών ζώων.\n",
        "\n",
        "#### K-means\n",
        "Ο αλγόριθμος ομαδοποίησης K-means είναι από του πιό διάσημους αλγορίθμους συσταδοποίησης με την ακόλουθη σειρά διαδικασιών. Αρχικά επιλέγονται τα k centroids τα οποία αποτελούν τα κέντρα των ομάδων. Στο επόμενο κομμάτι ο αλγόριθμος αναθέτει τα παραδείγματα στα κοντινότερα κέντρα και δημιουργεί τα νέα κέντρα των συστάδων υπολογίζοντας την μέση τιμή των παραδειγμάτων της ομάδας. Τέλος υπολογίζεται η διαφορά του παλιού και του νέου κέντρου και επαναλαμβάνεται η διαδικασία υπολογισμού των κέντρων. Τα βήματα αυτά επαναλαμβάνονται μέχρι η διαφορά να πέσει κάτω από ένα κατώφλι."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLRnH3DsyM7D"
      },
      "source": [
        "# PCA Analysis στο iris dataset\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "target_names = iris.target_names\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "X_r = pca.fit(X).transform(X)\n",
        "\n",
        "# Percentage of variance explained for each components\n",
        "print('explained variance ratio (first two components): %s'\n",
        "      % str(pca.explained_variance_ratio_))\n",
        "\n",
        "plt.figure()\n",
        "colors = ['navy', 'turquoise', 'darkorange']\n",
        "lw = 2\n",
        "\n",
        "for color, i, target_name in zip(colors, [0, 1, 2], target_names):\n",
        "    plt.scatter(X_r[y == i, 0], X_r[y == i, 1], color=color, alpha=.8, lw=lw,\n",
        "                label=target_name)\n",
        "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
        "plt.title('PCA of IRIS dataset')\n",
        "\n",
        "plt.figure()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Εφαρμογή k-means στο αποτέλεσμα της ανάλυσης PCA για 3 clusters\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "kmeans = KMeans(n_clusters=3, random_state=0)\n",
        "kmeans.fit(X_r)\n",
        "y_kmeans = kmeans.predict(X_r)\n",
        "\n",
        "plt.scatter(X_r[:, 0], X_r[:, 1], c=y_kmeans, s=50, cmap='viridis')\n",
        "\n",
        "centers = kmeans.cluster_centers_\n",
        "plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7Gd1Egi1O_5"
      },
      "source": [
        "### Κατηγοριοποίηση\n",
        "Η κατηγοριοποίηση ή ταξινόμηση είναι η διαδικασία πρόβλεψης της κατηγορίας ενός παραδείγματος. Οι κατηγορίες ή κλάσεις είναι οι διαφορετικές ομάδες που ανήκουν τα παραδείγματα. Στόχος της εκπαίδευσης των αλγορίθμων ταξινόμησης είναι η εύρεση κατάλληλης συνάρτησης f η οποία αντιστοιχεί τα διάφορα παραδείγματα x στις σωστές διακριτές κλάσεις y.\n",
        "\n",
        "Για παράδειγμα η ταξινόμηση τραγουδιών ανάλογα με το είδος τους είναι μία διαδικασία κατηγοριοποίησης.\n",
        "\n",
        "#### Support Vector Machines (SVMs)\n",
        "Το πρόβλημα που καλούνται να λύσουν τα SVMs είναι η εύρεση του υπερπεπιπέδου που χωρίζει καλύτερα τα σημεία δεδομένων στις σωστές κλάσεις. Πιο συγκεκριμένα επιχειρούν να μεγιστοποιήσουν το margin μεταξύ των vector points με την προϋπόθεση να ταξινομούνται σωστά(hard margin).![alt text](https://www.bogotobogo.com/python/scikit-learn/images/svm/SVM-Hyperplane-Maximizing-Margin.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cg5qtZb_WbT_"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Χωριζεται σε train/test set\n",
        "iris = datasets.load_iris()\n",
        "print(iris.data.shape, iris.target.shape)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    iris.data, iris.target, test_size=0.4, random_state=0)\n",
        "\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)\n",
        "\n",
        "model = svm.SVC(kernel='linear')\n",
        "clf = model.fit(X_train, y_train)\n",
        "# Ακρίβεια του ταξινομητή\n",
        "acc = clf.score(X_test, y_test)\n",
        "print('The accuracy is :', acc)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Πίνακας Σύγχυσης\n",
        "confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrWtuCRAGape"
      },
      "source": [
        "![alt text](http://rasbt.github.io/mlxtend/user_guide/evaluate/confusion_matrix_files/confusion_matrix_1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FJEKdnceOyh"
      },
      "source": [
        "#### Neural Networks\n",
        "Ταξινομητές που προσομοιάζουν την λειτουργία του εγκεφάλου με νευρώνες τον κάθε κόμβο και συνάψεις τα αντίστοιχα βάρη. Το σύνολο των βαρών μαζί με τα αντίστοιχα χαρακτηριστικά εισέρχονται στον κόμβο και αθροίζονται, στην συνέχεια υπολογίζεται το αποτέλεσμα της συνάρτησης ενεργοποίησης και διαδίδεται στο επόμενο επίπεδο. \n",
        "![alt text](https://isaacchanghau.github.io/img/deeplearning/activationfunction/intro.png)\n",
        "Ένα νευρωνικό δίκτυο αποτελέιται από τουλάχιστον ένα input layer και ένα output layer, ενώ μπορεί να αποτελείται απο πολλά hidden layers(Multilayer Perceptron). \n",
        "\n",
        "\n",
        "![alt text](http://neuralnetworksanddeeplearning.com/images/tikz11.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPBnPFtle6ab"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Χωριζεται σε train/test set\n",
        "iris = datasets.load_iris()\n",
        "iris.data.shape, iris.target.shape\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    iris.data, iris.target, test_size=0.2, random_state=0)\n",
        "\n",
        "# Εκπαίδευση multilayer perceptron με 2 hidden layers και 10 νευρώνες στο κάθε επίπεδο\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(10,10), alpha=1e-4, \n",
        "                    solver='sgd')\n",
        "\n",
        "mlp.fit(X_train, y_train)\n",
        "print(\"Test set score: %f\" % mlp.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}